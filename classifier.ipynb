{"cells":[{"cell_type":"code","execution_count":84,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1680265900564,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"},"user_tz":-120},"id":"cQn6tPPdSXfJ"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam\n","import torch\n","import torch.nn as nn\n","import csv\n","import numpy as np\n","import typing as t\n","import csv\n","from transformers import BertTokenizer, BertModel\n","from tqdm import tqdm\n","from sklearn.metrics import precision_recall_fscore_support"]},{"cell_type":"code","execution_count":85,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1680265900565,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"},"user_tz":-120},"id":"qjZAm7NCYBRM","outputId":"396a94f9-ede5-4a6f-b7e6-16498c42772b"},"outputs":[{"data":{"text/plain":["device(type='mps')"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cpu\")\n","\n","if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n","    device = torch.device(\"mps\")\n","\n","device"]},{"cell_type":"code","execution_count":86,"metadata":{"executionInfo":{"elapsed":1205,"status":"ok","timestamp":1680265901764,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"},"user_tz":-120},"id":"kVN60FyVT_kX"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',)"]},{"cell_type":"code","execution_count":87,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1680265901765,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"},"user_tz":-120},"id":"kfVVyp9-S6y3"},"outputs":[],"source":["class WikiData(Dataset):\n","  def __init__(self, csv_path:str = \"\", limit: int = 0):\n","    self.csv_path = csv_path\n","    self.limit = limit\n","    self.data = self._load_csv()\n","\n","  def _load_csv(self):\n","    rows = []\n","    i = 0\n","    with open(self.csv_path, \"r\", encoding=\"utf-8\") as f:\n","      reader = csv.reader(f, delimiter=\",\")\n","      for row in reader:\n","        if self.limit and i >= self.limit:\n","          break\n","        _id, label, text = row\n","        rows.append((_id, label, text))\n","        i += 1\n","    return rows\n","\n","  def __len__(self):\n","    return len(self.data)\n","  \n","  def __getitem__(self, idx: int):\n","    _id, label, text = self.data[idx]\n","    label = 0 if label == \"standard\" else 1\n","    return text, label"]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1680265901766,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"},"user_tz":-120},"id":"4oz27Nkac5Un","outputId":"c2984ee7-52c5-41be-e739-6cc4b57b8cad"},"outputs":[{"data":{"text/plain":["tensor([[[5, 5, 0],\n","         [6, 6, 1]],\n","\n","        [[7, 7, 1],\n","         [8, 8, 0]]])"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["a = torch.tensor([\n","    [[5, 5], [6, 6]],\n","    [[7, 7], [8, 8]],\n","])\n","\n","b = torch.tensor([\n","    [0, 1],\n","    [1, 0]\n","])\n","b = b.reshape((a.shape[0], -1, 1))\n","torch.cat((a, b), dim=2)"]},{"cell_type":"code","execution_count":89,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680265901766,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"},"user_tz":-120},"id":"M9vtQ-yqUXwr"},"outputs":[],"source":["class ReadabilityClassifier(nn.Module):\n","  def __init__(self,\n","               hidden_size: int = 126,\n","               n_lstm_layers: int = 1\n","               ):\n","    super().__init__()\n","\n","    self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n","\n","    for param in self.bert.parameters():\n","      param.requires_grad = False\n","\n","    self.lstm = nn.LSTM(\n","        input_size = 769,\n","        hidden_size = hidden_size,\n","        num_layers = n_lstm_layers,\n","        batch_first = True\n","    )\n","    self.linear = nn.Linear(hidden_size, 2)\n","    self.softmax = nn.LogSoftmax(dim=1)\n","  \n","  def forward(self, tokens):\n","    attention = tokens.attention_mask\n","    embedded = self.bert(**tokens).last_hidden_state\n","    attention = attention.reshape(embedded.shape[0], -1, 1)\n","    embedded = torch.cat((embedded, attention), dim=2)\n","    output, _ = self.lstm(embedded)\n","    output = output[:, -1, :]\n","    output = self.linear(output)\n","    sm = self.softmax(output)\n","    return sm\n"]},{"cell_type":"code","execution_count":90,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1680265901767,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"},"user_tz":-120},"id":"u5RjaNTuXiII"},"outputs":[],"source":["def train(\n","    model: ReadabilityClassifier, \n","    criterion: nn.Module,\n","    dataloader: DataLoader,\n","    optimizer,\n","    n_epochs: int = 1,\n","):\n","  for epoch in range(n_epochs):\n","    loop = tqdm(dataloader)\n","    losses = []\n","    for texts, labels in loop:\n","      optimizer.zero_grad()\n","      tokens = tokenizer(\n","          texts, \n","          return_tensors=\"pt\", \n","          padding=True, \n","          truncation=True\n","      ).to(device)\n","      labels = labels.to(device)\n","      output = model(tokens)\n","      loss = criterion(output, labels)\n","      losses.append(loss.item())\n","      loss.backward()\n","      optimizer.step()\n","    print(f\"Loss at epoch {epoch}: {round(sum(losses) / len(losses), 4)}\")\n","    \n","    torch.save({\n","        \"epoch\": epoch,\n","        \"model_state_dict\": model.state_dict(),\n","        \"optimizer_state_dict\": optimizer.state_dict(),\n","        \"loss\": sum(losses) / len(losses)\n","    }, f\"checkpoints/epoch_{epoch}.tar\")"]},{"cell_type":"code","execution_count":91,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680265901767,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"},"user_tz":-120},"id":"jbMpww3RiDOh"},"outputs":[],"source":["def evaluate(model: nn.Module, dataloader: DataLoader):\n","  y_true = []\n","  y_pred = []\n","  with torch.no_grad():\n","    loop = tqdm(dataloader)\n","    for texts, levels in loop:\n","      tokens = tokenizer(\n","          texts, \n","          return_tensors=\"pt\", \n","          padding=True, \n","          truncation=True\n","      ).to(device)\n","      levels = levels.to(device)\n","      output = model(tokens)\n","      output = output.argmax(dim=1).cpu().detach().numpy()\n","      levels = levels.cpu().detach().numpy()\n","      y_true.extend(levels)\n","      y_pred.extend(output)\n","    precision, recall, fscore, _ = precision_recall_fscore_support(\n","        y_true = levels, \n","        y_pred = output,\n","        labels=[0, 1],\n","    )\n","    print()\n","    print(\"Precision\", precision)\n","    print(\"Recall\", recall)\n","    print(\"Fscore\", fscore)\n","    return y_true, y_pred\n","      "]},{"cell_type":"code","execution_count":92,"metadata":{"executionInfo":{"elapsed":26822,"status":"ok","timestamp":1680265928581,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"},"user_tz":-120},"id":"sMEkOOdwN5PW"},"outputs":[],"source":["train_dataloader = DataLoader(\n","    WikiData(\"./distrib/dataset_train.csv\"),\n","    batch_size=50,\n","    shuffle=True\n",")"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inaC96JNX0MC","outputId":"f3760bee-3853-4a5d-8a64-b0e099894f4f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["model = ReadabilityClassifier()\n","model.to(device)\n","criterion = nn.NLLLoss()\n","optimizer = Adam(model.parameters(), lr=2e-5)\n","checkpoint = torch.load(\"checkpoints/full_e0.tar\", map_location=device)\n","# train(model, criterion, train_dataloader, optimizer, n_epochs=5)\n","model.load_state_dict(checkpoint[\"model_state_dict\"])\n"]},{"cell_type":"code","execution_count":94,"metadata":{"id":"4XZj_3aWis9a"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 800/800 [36:53<00:00,  2.77s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Precision [0.88461538 0.83333333]\n","Recall [0.85185185 0.86956522]\n","Fscore [0.86792453 0.85106383]\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["test_dataloader = DataLoader(\n","    WikiData(\"./distrib/dataset_test.csv\"),\n","    batch_size=50,\n","    shuffle=True,\n",")\n","\n","y_true, y_pred = evaluate(model, test_dataloader)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/waron97/nlp_for_readability_term_paper/blob/master/classifier.ipynb","timestamp":1680207323249}]},"gpuClass":"standard","kernelspec":{"display_name":"term-paper-nfLWpm6z-py3.9","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
