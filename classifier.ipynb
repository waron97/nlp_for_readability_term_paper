{"cells":[{"cell_type":"code","source":["!pip install transformers tokenizers torch torchvision scikit-learn numpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iEtSIjImKlGA","executionInfo":{"status":"ok","timestamp":1680265898481,"user_tz":-120,"elapsed":5845,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"}},"outputId":"33f8eb68-5b8a-4b88-9cd0-5ad8aae3a80b"},"execution_count":119,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.9/dist-packages (0.13.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.14.1+cu116)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.1.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hh00XktHSWHk","executionInfo":{"status":"ok","timestamp":1680265900564,"user_tz":-120,"elapsed":2089,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"}},"outputId":"15a62fd7-878b-4b37-f027-a50b332ba763"},"execution_count":120,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam\n","import torch\n","import torch.nn as nn\n","import csv\n","import numpy as np\n","import typing as t\n","import csv\n","from transformers import BertTokenizer, BertModel\n","from tqdm import tqdm\n","from sklearn.metrics import precision_recall_fscore_support"],"metadata":{"id":"cQn6tPPdSXfJ","executionInfo":{"status":"ok","timestamp":1680265900564,"user_tz":-120,"elapsed":11,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(device)"],"metadata":{"id":"qjZAm7NCYBRM","executionInfo":{"status":"ok","timestamp":1680265900565,"user_tz":-120,"elapsed":10,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"396a94f9-ede5-4a6f-b7e6-16498c42772b"},"execution_count":122,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',)"],"metadata":{"id":"kVN60FyVT_kX","executionInfo":{"status":"ok","timestamp":1680265901764,"user_tz":-120,"elapsed":1205,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"}}},"execution_count":123,"outputs":[]},{"cell_type":"code","source":["class WikiData(Dataset):\n","  def __init__(self, csv_path:str = \"\", limit: int = 0):\n","    self.csv_path = csv_path\n","    self.limit = limit\n","    self.data = self._load_csv()\n","\n","  def _load_csv(self):\n","    rows = []\n","    i = 0\n","    with open(self.csv_path, \"r\", encoding=\"utf-8\") as f:\n","      reader = csv.reader(f, delimiter=\",\")\n","      for row in reader:\n","        if self.limit and i >= self.limit:\n","          break\n","        _id, label, text = row\n","        rows.append((_id, label, text))\n","        i += 1\n","    return rows\n","\n","  def __len__(self):\n","    return len(self.data)\n","  \n","  def __getitem__(self, idx: int):\n","    _id, label, text = self.data[idx]\n","    label = 0 if label == \"standard\" else 1\n","    return text, label"],"metadata":{"id":"kfVVyp9-S6y3","executionInfo":{"status":"ok","timestamp":1680265901765,"user_tz":-120,"elapsed":11,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"}}},"execution_count":124,"outputs":[]},{"cell_type":"code","source":["a = torch.tensor([\n","    [[5, 5], [6, 6]],\n","    [[7, 7], [8, 8]],\n","])\n","\n","b = torch.tensor([\n","    [0, 1],\n","    [1, 0]\n","])\n","b = b.reshape((a.shape[0], -1, 1))\n","torch.cat((a, b), dim=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4oz27Nkac5Un","executionInfo":{"status":"ok","timestamp":1680265901766,"user_tz":-120,"elapsed":10,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"}},"outputId":"c2984ee7-52c5-41be-e739-6cc4b57b8cad"},"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[5, 5, 0],\n","         [6, 6, 1]],\n","\n","        [[7, 7, 1],\n","         [8, 8, 0]]])"]},"metadata":{},"execution_count":125}]},{"cell_type":"code","source":["class ReadabilityClassifier(nn.Module):\n","  def __init__(self,\n","               hidden_size: int = 126,\n","               n_lstm_layers: int = 1\n","               ):\n","    super().__init__()\n","\n","    self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n","\n","    for param in self.bert.parameters():\n","      param.requires_grad = False\n","\n","    self.lstm = nn.LSTM(\n","        input_size = 769,\n","        hidden_size = hidden_size,\n","        num_layers = n_lstm_layers,\n","        batch_first = True\n","    )\n","    self.linear = nn.Linear(hidden_size, 2)\n","    self.softmax = nn.LogSoftmax(dim=1)\n","  \n","  def forward(self, tokens):\n","    attention = tokens.attention_mask\n","    embedded = self.bert(**tokens).last_hidden_state\n","    attention = attention.reshape(embedded.shape[0], -1, 1)\n","    embedded = torch.cat((embedded, attention), dim=2)\n","    output, _ = self.lstm(embedded)\n","    output = output[:, -1, :]\n","    output = self.linear(output)\n","    sm = self.softmax(output)\n","    return sm\n"],"metadata":{"id":"M9vtQ-yqUXwr","executionInfo":{"status":"ok","timestamp":1680265901766,"user_tz":-120,"elapsed":8,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"}}},"execution_count":126,"outputs":[]},{"cell_type":"code","source":["def train(\n","    model: ReadabilityClassifier, \n","    criterion: nn.Module,\n","    dataloader: DataLoader,\n","    optimizer,\n","    n_epochs: int = 1,\n","):\n","  for epoch in range(n_epochs):\n","    loop = tqdm(dataloader)\n","    losses = []\n","    for texts, labels in loop:\n","      optimizer.zero_grad()\n","      tokens = tokenizer(\n","          texts, \n","          return_tensors=\"pt\", \n","          padding=True, \n","          truncation=True\n","      ).to(device)\n","      labels = labels.to(device)\n","      output = model(tokens)\n","      loss = criterion(output, labels)\n","      losses.append(loss.item())\n","      loss.backward()\n","      optimizer.step()\n","    print(f\"Loss at epoch {epoch}: {round(sum(losses) / len(losses), 4)}\")\n","    \n","    torch.save({\n","        \"epoch\": epoch,\n","        \"model_state_dict\": model.state_dict(),\n","        \"optimizer_state_dict\": optimizer.state_dict(),\n","        \"loss\": sum(losses) / len(losses)\n","    }, f\"checkpoints/epoch_{epoch}.tar\")"],"metadata":{"id":"u5RjaNTuXiII","executionInfo":{"status":"ok","timestamp":1680265901767,"user_tz":-120,"elapsed":9,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"}}},"execution_count":127,"outputs":[]},{"cell_type":"code","source":["def evaluate(model: nn.Module, dataloader: DataLoader):\n","  y_true = []\n","  y_pred = []\n","  with torch.no_grad():\n","    loop = tqdm(dataloader)\n","    for texts, levels in loop:\n","      tokens = tokenizer(\n","          texts, \n","          return_tensors=\"pt\", \n","          padding=True, \n","          truncation=True\n","      ).to(device)\n","      levels = levels.to(device)\n","      output = model(tokens)\n","      output = output.argmax(dim=1).cpu().detach().numpy()\n","      levels = levels.cpu().detach().numpy()\n","      y_true.extend(levels)\n","      y_pred.extend(output)\n","    precision, recall, fscore, _ = precision_recall_fscore_support(\n","        y_true = levels, \n","        y_pred = output,\n","        average = \"micro\"\n","    )\n","    print()\n","    print(\"Precision\", precision)\n","    print(\"Recall\", recall)\n","    print(\"Fscore\", fscore)\n","      "],"metadata":{"id":"jbMpww3RiDOh","executionInfo":{"status":"ok","timestamp":1680265901767,"user_tz":-120,"elapsed":8,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"}}},"execution_count":128,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(\n","    WikiData(\"./drive/MyDrive/Colab Notebooks/dataset_train.csv\"),\n","    batch_size=50,\n","    shuffle=True\n",")"],"metadata":{"id":"sMEkOOdwN5PW","executionInfo":{"status":"ok","timestamp":1680265928581,"user_tz":-120,"elapsed":26822,"user":{"displayName":"Winkler Áron","userId":"05619291698364576744"}}},"execution_count":129,"outputs":[]},{"cell_type":"code","source":["model = ReadabilityClassifier()\n","model.to(device)\n","criterion = nn.NLLLoss()\n","optimizer = Adam(model.parameters(), lr=2e-5)\n","train(model, criterion, train_dataloader, optimizer, n_epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inaC96JNX0MC","outputId":"f3760bee-3853-4a5d-8a64-b0e099894f4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","  0%|          | 50/32058 [00:55<9:59:22,  1.12s/it]"]}]},{"cell_type":"code","source":["test_dataloader = DataLoader(\n","    WikiData(\"./drive/MyDrive/Colab Notebooks/dataset_test.csv\", limit=100),\n","    batch_size=50,\n","    shuffle=True,\n",")\n","\n","evaluate(model, test_dataloader)"],"metadata":{"id":"4XZj_3aWis9a"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"term-paper-nfLWpm6z-py3.9","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"colab":{"provenance":[{"file_id":"https://github.com/waron97/nlp_for_readability_term_paper/blob/master/classifier.ipynb","timestamp":1680207323249}]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}